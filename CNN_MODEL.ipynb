{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "oYOQBdMOB6_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fum_PIcsBu0",
        "outputId": "eb89fd13-0e70-4afd-e105-d278aa485c11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy opencv-python scikit-learn tensorflow keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests"
      ],
      "metadata": {
        "id": "F4YE1eUqsPbu"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "bold text# Create a directory to store images locally"
      ],
      "metadata": {
        "id": "TeS84u3PvH2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = 'images'\n",
        "os.makedirs(image_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "TJRxgfORtTZR"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to download images from URLs and save locally\n"
      ],
      "metadata": {
        "id": "BsfJnBKWvLFA"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images(image_links):\n",
        "    for i, link in enumerate(image_links):\n",
        "        try:\n",
        "            response = requests.get(link)\n",
        "            if response.status_code == 200:\n",
        "                with open(f\"{image_folder}/image_{i+1}.jpg\", 'wb') as file:\n",
        "                    file.write(response.content)\n",
        "            else:\n",
        "                print(f\"Failed to download image {i+1}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading image {i+1}: {e}\")"
      ],
      "metadata": {
        "id": "oNevf0DBvOFY"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        " from google.colab import drive\n",
        " import pandas as pd"
      ],
      "metadata": {
        "id": "mN9D_hLlvZRB"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uk4HXuCxPzR",
        "outputId": "4b2fa15e-3be0-4968-f7bb-8d9882ccc04a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'drive/My Drive/data'"
      ],
      "metadata": {
        "id": "DfPP65CcxR6K"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(path+'/COMBINED_TRAIN_DATA (1).csv', encoding='utf-8')\n",
        "\n"
      ],
      "metadata": {
        "id": "_yDPMxk_xZbl"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_images(train_data['image_link'].tolist())"
      ],
      "metadata": {
        "id": "yKcr9KUAxhvW"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Image Preprocessing: Resizing, Normalization, and Augmentation\n",
        "\n",
        "Resize images to a consistent size (e.g., 128x128 pixels).\n",
        "Normalize the pixel values (scale them between 0 and 1).\n",
        "Optionally apply data augmentation (e.g., flipping, rotating, etc.)."
      ],
      "metadata": {
        "id": "OpjIAi6XyyY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z97Ej0ynxpDx",
        "outputId": "49c65b40-fd49-4b29-94de-9c7960b1f38c"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2  # OpenCV for image processing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "QitdMuYOy-Mq"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_SIZE = (128, 128)\n"
      ],
      "metadata": {
        "id": "CTjoPg-3zBGO"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(image_path, target_size=TARGET_SIZE):\n",
        "    # Load the image using OpenCV\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Resize the image to the target size\n",
        "    img = cv2.resize(img, target_size)\n",
        "\n",
        "    # Normalize the image (scale pixel values to the range [0, 1])\n",
        "    img = img.astype('float32') / 255.0\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "b1gGPFBJzFIV"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation using Keras ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,        # Rotate images by up to 20 degrees\n",
        "    width_shift_range=0.1,    # Shift the image width by up to 10%\n",
        "    height_shift_range=0.1,   # Shift the image height by up to 10%\n",
        "    horizontal_flip=True,     # Flip the images horizontally\n",
        "    fill_mode='nearest'       # Fill in new pixels when shifting\n",
        ")"
      ],
      "metadata": {
        "id": "7aS9Sf5rzIVF"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to augment a single image\n",
        "def augment_image(img):\n",
        "    img = np.expand_dims(img, axis=0)  # Expand dims for batch compatibility\n",
        "    augmented_images = datagen.flow(img, batch_size=1)\n",
        "    return augmented_images[0][0]  # Return the augmented image"
      ],
      "metadata": {
        "id": "udA4TFSzzdJm"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Load and Preprocess Images for Training and Testing"
      ],
      "metadata": {
        "id": "CfDZcrEPzmNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_folder = 'images'"
      ],
      "metadata": {
        "id": "Loi20nkazf39"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_images(image_filenames, folder=image_folder, augment=False):\n",
        "    images = []\n",
        "    for filename in image_filenames:\n",
        "        image_path = os.path.join(folder, filename)\n",
        "        img = preprocess_image(image_path)\n",
        "\n",
        "        # Optionally augment the image\n",
        "        if augment:\n",
        "            img = augment_image(img)\n",
        "\n",
        "        images.append(img)\n",
        "\n",
        "    return np.array(images)\n"
      ],
      "metadata": {
        "id": "zw18B7wm1XDO"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data =  pd.read_csv(path+'/COMBINED_TRAIN_DATA (1).csv', encoding='utf-8')\n",
        "test_data =  pd.read_csv(path+'/TEST.csv', encoding='utf-8')\n",
        "T_D = train_data\n",
        "TEST_DATA = test_data\n",
        "print(T_D)\n",
        "print(TEST_DATA)"
      ],
      "metadata": {
        "id": "If4maM9N1aYi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d7e77b4-c20e-498a-eef7-f34df8332dbd"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    index                                         image_link  group_id  \\\n",
            "0       1  https://m.media-amazon.com/images/I/71Zy+qaX82...         3   \n",
            "1       2  https://m.media-amazon.com/images/I/619xuNVks4...         4   \n",
            "2       3  https://m.media-amazon.com/images/I/61+uFY1+-d...         4   \n",
            "3       4  https://m.media-amazon.com/images/I/413lP0yIzL...         1   \n",
            "4       5  https://m.media-amazon.com/images/I/41KG3OYJo0...         3   \n",
            "5       6  https://m.media-amazon.com/images/I/81vqHyDCSC...         2   \n",
            "6       7  https://m.media-amazon.com/images/I/71GLMJ7TQi...         2   \n",
            "7       8  https://m.media-amazon.com/images/I/41uC6f6q+B...         2   \n",
            "8       9  https://m.media-amazon.com/images/I/41aIgv8HTE...         2   \n",
            "9      10  https://m.media-amazon.com/images/I/71fhaUR7VG...         2   \n",
            "10     11  https://m.media-amazon.com/images/I/21q4I7ziVq...         2   \n",
            "11     12  https://m.media-amazon.com/images/I/61MV+cJP9U...         6   \n",
            "12     13  https://m.media-amazon.com/images/I/51KpNo662A...         5   \n",
            "13     14  https://m.media-amazon.com/images/I/31bV3X6lxU...         5   \n",
            "14     15  https://m.media-amazon.com/images/I/318oB+427u...         1   \n",
            "\n",
            "         entity_name              entity_value  \n",
            "0     item_dimension                   39.6 cm  \n",
            "1           item_vol                     189 L  \n",
            "2           item_vol                     602 L  \n",
            "3       item_voltage                      12 V  \n",
            "4     item_dimension                  39.62 cm  \n",
            "5     item_dimension     165.1 x 75.6 x 8.9 mm  \n",
            "6     item_dimension     160.8 x 78.1 x 7.7 mm  \n",
            "7     item_dimension     163.2 x 73.6 x 8.7 mm  \n",
            "8     item_dimension     164.3 x 74.6 x 8.4 mm  \n",
            "9     item_dimension     158.5 x 73.3 x 8.4 mm  \n",
            "10    item_dimension     164.5 x 75.2 x 8.9 mm  \n",
            "11                AC  22.2D x 92W x 31.6H Cm\\n  \n",
            "12  HAIR STRAIGHTNER                   19*85mm  \n",
            "13        HAIR DRYER                    1000 W  \n",
            "14        POWER BANK                     22.5W  \n",
            "   index                                         image_link  group_id  \\\n",
            "0      1  https://m.media-amazon.com/images/I/41qOe3IMm1...         3   \n",
            "1      2  https://m.media-amazon.com/images/I/31U6TIHVxF...         4   \n",
            "2      3  https://m.media-amazon.com/images/I/51hA1mvqar...         1   \n",
            "3      4  https://m.media-amazon.com/images/I/71VQXjN6R7...         2   \n",
            "4      5  https://m.media-amazon.com/images/I/712SeOsnKU...         2   \n",
            "\n",
            "      entity_name  \n",
            "0  item_dimension  \n",
            "1        item_vol  \n",
            "2    item_voltage  \n",
            "3  item_dimension  \n",
            "4  item_dimension  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of image filenames (as used in the earlier step)\n",
        "train_image_filenames = [f'image_{i+1}.jpg' for i in range(train_data.shape[0])]\n",
        "test_image_filenames = [f'image_{i+1}.jpg' for i in range(test_data.shape[0])]"
      ],
      "metadata": {
        "id": "vDylwwvW1wpg"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_images = load_and_preprocess_images(train_image_filenames, augment=True)  # With augmentation\n",
        "X_test_images = load_and_preprocess_images(test_image_filenames)  # Without augmentation"
      ],
      "metadata": {
        "id": "4mSIr2ca1zv4"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feeding Preprocessed Images into the Model"
      ],
      "metadata": {
        "id": "bF9N0uGp2DIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ],
      "metadata": {
        "id": "JEJOHWYr140I"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a simple CNN model"
      ],
      "metadata": {
        "id": "3bTfBuO32OXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(1))  # Output layer for regression (e.g., predicting dimensions or weight)\n",
        "    return model"
      ],
      "metadata": {
        "id": "t9X8F0g92HjV"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape based on image size and color channels (3 for RGB)\n",
        "input_shape = (TARGET_SIZE[0], TARGET_SIZE[1], 3)"
      ],
      "metadata": {
        "id": "iNWZW-ky2Znw"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and compile the CNN model\n",
        "model = create_model(input_shape)\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtVA2hwH2dfO",
        "outputId": "45e8cb4b-6818-446c-b642-19fdf9b243e8"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "\n",
        "# Function to extract the numeric value from the string\n",
        "def extract_numeric_value(entity_value):\n",
        "    # Use a regular expression to find numeric values in the string\n",
        "    match = re.search(r\"[-+]?\\d*\\.\\d+|\\d+\", entity_value)\n",
        "    if match:\n",
        "        # Return the numeric value as a float\n",
        "        return float(match.group())\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Apply the function to the 'entity_value' column\n",
        "train_data['numeric_value'] = train_data['entity_value'].apply(extract_numeric_value)\n",
        "\n",
        "# Now, you can safely convert the extracted numeric values to float for your target variable\n",
        "y_train = train_data['numeric_value']\n",
        "\n",
        "# Check if there are any missing values in the new 'numeric_value' column\n",
        "print(train_data['numeric_value'].isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Zlhb3E2jeu",
        "outputId": "6e603ffd-4495-4ea8-c51c-2de901e3b282"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with missing values (optional, depending on your task)\n",
        "train_data.dropna(subset=['numeric_value'], inplace=True)\n",
        "\n",
        "# Or fill missing values with a default (e.g., 0)\n",
        "train_data['numeric_value'].fillna(0, inplace=True)\n",
        "\n",
        "# Now you can use 'numeric_value' as your target variable\n",
        "y_train = train_data['numeric_value']"
      ],
      "metadata": {
        "id": "9lwaK5vH3t-U"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_numeric(value):\n",
        "    # Keep only numeric characters and decimal point\n",
        "    return ''.join(char for char in value if char.isdigit() or char == '.')"
      ],
      "metadata": {
        "id": "tUYCTtse4El1"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract numeric values from the string\n",
        "def extract_dimensions(value):\n",
        "    # Find all numeric values with optional decimal points\n",
        "    numbers = re.findall(r'\\d+\\.\\d+|\\d+', value)\n",
        "    # Convert extracted values to float\n",
        "    return [float(num) for num in numbers]"
      ],
      "metadata": {
        "id": "fexll55f2m4X"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the extraction function\n",
        "train_data['entity_value'] = train_data['entity_value'].apply(extract_dimensions)"
      ],
      "metadata": {
        "id": "wuLrbrH33nQj"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the extraction function\n",
        "print(train_data)\n",
        "T_D = train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WcAaLNQ6D6G",
        "outputId": "c435a888-cd89-46d7-db5e-77fafbffa1ff"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    index                                         image_link  group_id  \\\n",
            "0       1  https://m.media-amazon.com/images/I/71Zy+qaX82...         3   \n",
            "1       2  https://m.media-amazon.com/images/I/619xuNVks4...         4   \n",
            "2       3  https://m.media-amazon.com/images/I/61+uFY1+-d...         4   \n",
            "3       4  https://m.media-amazon.com/images/I/413lP0yIzL...         1   \n",
            "4       5  https://m.media-amazon.com/images/I/41KG3OYJo0...         3   \n",
            "5       6  https://m.media-amazon.com/images/I/81vqHyDCSC...         2   \n",
            "6       7  https://m.media-amazon.com/images/I/71GLMJ7TQi...         2   \n",
            "7       8  https://m.media-amazon.com/images/I/41uC6f6q+B...         2   \n",
            "8       9  https://m.media-amazon.com/images/I/41aIgv8HTE...         2   \n",
            "9      10  https://m.media-amazon.com/images/I/71fhaUR7VG...         2   \n",
            "10     11  https://m.media-amazon.com/images/I/21q4I7ziVq...         2   \n",
            "11     12  https://m.media-amazon.com/images/I/61MV+cJP9U...         6   \n",
            "12     13  https://m.media-amazon.com/images/I/51KpNo662A...         5   \n",
            "13     14  https://m.media-amazon.com/images/I/31bV3X6lxU...         5   \n",
            "14     15  https://m.media-amazon.com/images/I/318oB+427u...         1   \n",
            "\n",
            "         entity_name        entity_value  numeric_value  \n",
            "0     item_dimension              [39.6]          39.60  \n",
            "1           item_vol             [189.0]         189.00  \n",
            "2           item_vol             [602.0]         602.00  \n",
            "3       item_voltage              [12.0]          12.00  \n",
            "4     item_dimension             [39.62]          39.62  \n",
            "5     item_dimension  [165.1, 75.6, 8.9]         165.10  \n",
            "6     item_dimension  [160.8, 78.1, 7.7]         160.80  \n",
            "7     item_dimension  [163.2, 73.6, 8.7]         163.20  \n",
            "8     item_dimension  [164.3, 74.6, 8.4]         164.30  \n",
            "9     item_dimension  [158.5, 73.3, 8.4]         158.50  \n",
            "10    item_dimension  [164.5, 75.2, 8.9]         164.50  \n",
            "11                AC  [22.2, 92.0, 31.6]          22.20  \n",
            "12  HAIR STRAIGHTNER        [19.0, 85.0]          19.00  \n",
            "13        HAIR DRYER            [1000.0]        1000.00  \n",
            "14        POWER BANK              [22.5]          22.50  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "train_data = pd.DataFrame({\n",
        "    'entity_value': ['165.1 MM * 175.6MM * 8.9 MM', '39.6 cm', '20.4 kg', '15.2 g']\n",
        "})\n",
        "\n",
        "# Function to extract dimensions or handle non-dimension entries\n",
        "def extract_or_handle(value):\n",
        "    numbers = re.findall(r'\\d+\\.\\d+|\\d+', value)\n",
        "    numbers = [float(num) for num in numbers]\n",
        "    if len(numbers) == 3:\n",
        "        return numbers  # Return as list if 3 dimensions\n",
        "    else:\n",
        "        return np.nan  # Return NaN for non-dimension entries\n",
        "\n",
        "# Apply the function\n",
        "train_data['entity_value'] = train_data['entity_value'].apply(extract_or_handle)\n",
        "\n",
        "# Check the result\n",
        "print(train_data)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRrJCbqb6NtS",
        "outputId": "571a38f3-ea99-4a1c-81e0-54eb9eca983f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          entity_value\n",
            "0  [165.1, 175.6, 8.9]\n",
            "1                  NaN\n",
            "2                  NaN\n",
            "3                  NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the preprocessed images\n",
        "model.fit(X_train_images, y_train, epochs=10, batch_size=16)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLqAkMvi6UcX",
        "outputId": "790485f6-58a7-4ea1-f029-b60126b81dc6"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - loss: 104110.6953\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 97772.0859\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 89565.0156\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - loss: 79719.2500\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409ms/step - loss: 70411.4297\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - loss: 66702.6016\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - loss: 72676.0547\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 624ms/step - loss: 73755.9297\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - loss: 69857.0312\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 591ms/step - loss: 66069.6094\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c7d045f77f0>"
            ]
          },
          "metadata": {},
          "execution_count": 205
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrgSHzzv6sKz",
        "outputId": "2262ee07-7d5b-4d66-8edf-b60ca08ecfe8"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_predictions(predictions, entity_name):\n",
        "    formatted_predictions = []\n",
        "    for pred in predictions:\n",
        "        if entity_name == 'item_weight':\n",
        "            formatted_predictions.append(f\"{pred[0]:.2f} kg\")  # Example: weight in kilograms\n",
        "        elif entity_name == 'item_dimension':\n",
        "            formatted_predictions.append(f\"{pred[0]:.2f} cm\")  # Example: dimensions in centimeters\n",
        "    return formatted_predictions"
      ],
      "metadata": {
        "id": "S2Bx3Q2V_mc5"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = format_predictions(predictions, test_data['entity_name'].iloc[0])"
      ],
      "metadata": {
        "id": "J9p-SDnm_r7Z"
      },
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.DataFrame({'index': test_data['index'], 'prediction': test_predictions})"
      ],
      "metadata": {
        "id": "we43hNaZ_uwQ"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import pytesseract\n",
        "import re\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "metadata": {
        "id": "cMH7Amn0_1bP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec411866-2012-4c4c-b531-9a01a130a2ed"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "pbsQCEDCsKfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "   print(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI1y2mqw_yxz",
        "outputId": "65ba4ebe-e56c-4cd1-c016-3f307314e29f"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   index prediction\n",
            "0      1  226.64 cm\n",
            "1      2  142.93 cm\n",
            "2      3  206.14 cm\n",
            "3      4  211.72 cm\n",
            "4      5  201.08 cm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZN581bO1yQJM"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "T_D_split, val_data_split = train_test_split(T_D, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "p7BWQhNIyTIl"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.columns)\n",
        "print(test_data.columns)\n",
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9uzFTNlyVSX",
        "outputId": "21cd80ed-55eb-4010-91d4-dfd6b4f5d248"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['entity_value'], dtype='object')\n",
            "Index(['index', 'image_link', 'group_id', 'entity_name'], dtype='object')\n",
            "          entity_value\n",
            "0  [165.1, 175.6, 8.9]\n",
            "1                  NaN\n",
            "2                  NaN\n",
            "3                  NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VwfDfkrLy3Rt"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = T_D_split['image_link']  # Features (image links)\n",
        "y_train = T_D_split['entity_value']  # Target variable (actual values)\n",
        "X_val = val_data_split['image_link']  # Validation features\n",
        "y_val = val_data_split['entity_value']"
      ],
      "metadata": {
        "id": "JneKuryCzfoD"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_val.apply(lambda x: x)  # Dummy prediction to match ground truth\n",
        "\n",
        "# Step 3: Format both predictions and actual values\n",
        "def extract_numeric_string(val):\n",
        "    \"\"\"Helper function to standardize the format of predictions and ground truth\"\"\"\n",
        "    if isinstance(val, str):\n",
        "        return val.strip().lower()\n",
        "    return str(val)"
      ],
      "metadata": {
        "id": "t7sehBRD1Gwb"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = y_val.apply(extract_numeric_string)\n",
        "y_pred = np.array([extract_numeric_string(val) for val in y_pred])"
      ],
      "metadata": {
        "id": "7tLWozKK4Nuw"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(y_val, y_pred, average='micro')  # Use 'micro' for multi-class problems\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZZzbKfo4SBQ",
        "outputId": "c29806e8-2296-43d0-8300-307222507bee"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1cNwuzz4T1b"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}